{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62884e25-34f2-4e49-af10-be6dfcd8ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "\n",
    "# -------------------------\n",
    "# 1. Creating new features\n",
    "# -------------------------\n",
    "df[\"Total_Spending\"] = (\n",
    "    df[\"MntWines\"] +\n",
    "    df[\"MntFruits\"] +\n",
    "    df[\"MntMeatProducts\"] +\n",
    "    df[\"MntFishProducts\"] +\n",
    "    df[\"MntSweetProducts\"] +\n",
    "    df[\"MntGoldProds\"]\n",
    ")\n",
    "\n",
    "df[\"Children\"] = df[\"Kidhome\"] + df[\"Teenhome\"]\n",
    "df[\"Premium_Products\"] = df[\"MntWines\"] + df[\"MntMeatProducts\"]\n",
    "df[\"Age\"] = 2025 - df[\"Year_Birth\"]\n",
    "df[\"Is_Parent\"] = (df[\"Children\"] > 0).astype(int)\n",
    "df[\"Total_Accepted_Campaigns\"] = (\n",
    "    df[\"AcceptedCmp1\"] +\n",
    "    df[\"AcceptedCmp2\"] +\n",
    "    df[\"AcceptedCmp3\"] +\n",
    "    df[\"AcceptedCmp4\"] +\n",
    "    df[\"AcceptedCmp5\"] +\n",
    "    df[\"Response\"]\n",
    ")\n",
    "df[\"Loyalty_Years\"] = 2025 - pd.to_datetime(df[\"Dt_Customer\"], dayfirst=True).dt.year\n",
    "\n",
    "# -------------------------\n",
    "# 2. Define numeric and categorical columns for preprocessing\n",
    "# -------------------------\n",
    "numeric_features = [\n",
    "    'Age', 'Income', 'Total_Spending', 'Children',\n",
    "    'Total_Accepted_Campaigns', 'Recency', 'Loyalty_Years',\n",
    "    'MntWines', 'MntFruits', 'MntMeatProducts',\n",
    "    'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
    "    'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n",
    "    'NumStorePurchases', 'NumWebVisitsMonth', 'Premium_Products',\n",
    "    'Is_Parent'\n",
    "]\n",
    "\n",
    "categorical_features = ['Education', 'Marital_Status']\n",
    "\n",
    "# -------------------------\n",
    "# 3. ColumnTransformer: Scaling numeric + OneHotEncoding categorical\n",
    "# -------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "X_preprocessed = preprocessor.fit_transform(df)\n",
    "\n",
    "print(f\"Shape after full preprocessing (numeric + one-hot): {X_preprocessed.shape}\")\n",
    "\n",
    "# -------------------------\n",
    "# 4. Extract ONLY the scaled numeric part for clustering\n",
    "# -------------------------\n",
    "n_numeric = len(numeric_features)\n",
    "X_for_clustering = X_preprocessed[:, :n_numeric]  # First n_numeric columns are the scaled numerics\n",
    "\n",
    "print(f\"Shape for clustering (numeric only, already scaled): {X_for_clustering.shape}\")\n",
    "print(\"â†’ No duplicate scaling! We use the scaled numerics directly from ColumnTransformer.\")\n",
    "\n",
    "# -------------------------\n",
    "# 5. Find optimal k using Silhouette Score\n",
    "# -------------------------\n",
    "k_range = range(2, 10)\n",
    "silhouette_scores = {}\n",
    "\n",
    "print(\"\\nComputing Silhouette Scores for different k...\")\n",
    "for k in k_range:\n",
    "    np.random.seed(42)\n",
    "    initial_medoids = np.random.choice(len(X_for_clustering), k, replace=False).tolist()\n",
    "    \n",
    "    kmedoids_instance = kmedoids(X_for_clustering.tolist(), initial_medoids, data_type='points')\n",
    "    kmedoids_instance.process()\n",
    "    \n",
    "    clusters = kmedoids_instance.get_clusters()\n",
    "    \n",
    "    labels = np.full(len(X_for_clustering), -1, dtype=int)\n",
    "    for cluster_id, cluster in enumerate(clusters):\n",
    "        for idx in cluster:\n",
    "            labels[idx] = cluster_id\n",
    "    \n",
    "    sil = silhouette_score(X_for_clustering, labels)\n",
    "    silhouette_scores[k] = sil\n",
    "    print(f\"k = {k} â†’ Silhouette Score = {sil:.4f}\")\n",
    "\n",
    "optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
    "best_sil = silhouette_scores[optimal_k]\n",
    "\n",
    "print(\"\\n===== Optimal K Result =====\")\n",
    "print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "print(f\"Best Silhouette Score: {best_sil:.4f}\")\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(list(silhouette_scores.keys()), list(silhouette_scores.values()), marker='o', color='teal')\n",
    "plt.title('Silhouette Score vs. Number of Clusters')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# 6. Final K-Medoids clustering with optimal_k\n",
    "# -------------------------\n",
    "np.random.seed(42)\n",
    "initial_medoids_final = np.random.choice(len(X_for_clustering), optimal_k, replace=False).tolist()\n",
    "\n",
    "kmedoids_final = kmedoids(X_for_clustering.tolist(), initial_medoids_final, data_type='points')\n",
    "kmedoids_final.process()\n",
    "\n",
    "final_clusters = kmedoids_final.get_clusters()\n",
    "final_labels = np.full(len(X_for_clustering), -1, dtype=int)\n",
    "for cluster_id, cluster in enumerate(final_clusters):\n",
    "    for idx in cluster:\n",
    "        final_labels[idx] = cluster_id\n",
    "\n",
    "df['Cluster_KMedoids'] = final_labels\n",
    "\n",
    "# -------------------------\n",
    "# 7. Cluster Profiles (Numeric means + Categorical modes)\n",
    "# -------------------------\n",
    "# Numeric profiles\n",
    "cluster_profiles_numeric = df.groupby('Cluster_KMedoids')[numeric_features].mean().round(2)\n",
    "\n",
    "# Categorical profiles (most common value)\n",
    "cluster_profiles_cat = df.groupby('Cluster_KMedoids')[categorical_features].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else 'None'\n",
    ")\n",
    "\n",
    "print(\"\\n===== Cluster Profiles - Numeric Means =====\")\n",
    "print(cluster_profiles_numeric)\n",
    "\n",
    "print(\"\\n===== Cluster Profiles - Most Common Categorical Values =====\")\n",
    "print(cluster_profiles_cat)\n",
    "\n",
    "print(\"\\n===== Cluster Sizes =====\")\n",
    "cluster_sizes = df['Cluster_KMedoids'].value_counts().sort_index()\n",
    "for cluster in cluster_sizes.index:\n",
    "    size = cluster_sizes[cluster]\n",
    "    perc = (size / len(df) * 100).round(2)\n",
    "    print(f\"Cluster {cluster}: {size} customers ({perc}%)\")\n",
    "\n",
    "# -------------------------\n",
    "# 8. Business Insights & Recommendations\n",
    "# -------------------------\n",
    "print(\"\\n===== Business Insights & Marketing Recommendations =====\")\n",
    "overall_mean_income = df['Income'].mean()\n",
    "overall_mean_spending = df['Total_Spending'].mean()\n",
    "\n",
    "for cluster in sorted(df['Cluster_KMedoids'].unique()):\n",
    "    profile_num = cluster_profiles_numeric.loc[cluster]\n",
    "    profile_cat = cluster_profiles_cat.loc[cluster]\n",
    "    size = cluster_sizes[cluster]\n",
    "    perc = (size / len(df) * 100).round(2)\n",
    "    \n",
    "    print(f\"\\nCluster {cluster} ({size} customers, {perc}% of total):\")\n",
    "    print(f\" - Most common Education: {profile_cat['Education']}\")\n",
    "    print(f\" - Most common Marital Status: {profile_cat['Marital_Status']}\")\n",
    "    \n",
    "    if (profile_num['Income'] > overall_mean_income and\n",
    "        profile_num['Total_Spending'] > overall_mean_spending and\n",
    "        profile_num['Children'] < 1):\n",
    "        print(\" â†’ High-Value Premium Customers\")\n",
    "        print(\"   Recommendation: Luxury campaigns focused on wines and premium meats.\")\n",
    "    \n",
    "    elif profile_num['Children'] >= 1:\n",
    "        print(\" â†’ Family-Oriented Customers\")\n",
    "        print(\"   Recommendation: Family bundles, fruits, sweets, and fish promotions.\")\n",
    "    \n",
    "    elif profile_num['Income'] < overall_mean_income:\n",
    "        print(\" â†’ Budget-Conscious Customers\")\n",
    "        print(\"   Recommendation: Deals, discounts, and web-based promotions.\")\n",
    "    \n",
    "    else:\n",
    "        print(\" â†’ Balanced/General Customers\")\n",
    "        print(\"   Recommendation: Broad campaigns or A/B testing.\")\n",
    "\n",
    "# -------------------------\n",
    "# 9. PCA Visualization of Clusters\n",
    "# -------------------------\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_for_clustering)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "                      c=final_labels, cmap='viridis', alpha=0.7, s=50)\n",
    "plt.title('K-Medoids Clusters (PCA 2D Projection - Numeric Features)')\n",
    "plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# 10. Final Summary\n",
    "# -------------------------\n",
    "print(\"\\n===== Summary =====\")\n",
    "print(\"â€¢ Preprocessing done once with ColumnTransformer (scaling + encoding).\")\n",
    "print(\"â€¢ Only scaled numeric features used for K-Medoids â†’ clean distances, no distortion.\")\n",
    "print(\"â€¢ Categorical features used only for profiling â†’ rich business insights.\")\n",
    "print(\"â€¢ K-Medoids chosen for robustness against outliers.\")\n",
    "print(\"â€¢ Ready for production: the same preprocessor can be saved and reused for new customers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051fe22-9693-444f-b631-1350fc2e268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Ù„Ø§ØŒ Ø§Ù„ØªØºÙŠÙŠØ± Ù…Ø´ Ù‡ÙŠØ£Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆØ¯ÙŠÙ† Ø¯ÙˆÙ„ Ø®Ø§Ù„Øµ! 100% Ø¢Ù…Ù†ÙŠÙ†! âœ…**\n",
    "\n",
    "Ø®Ù„ÙŠÙ†ÙŠ Ø£ÙˆØ¶Ø­Ù„Ùƒ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ù„ÙŠÙ‡ØŒ ÙˆØ£Ø¯ÙŠÙ„Ùƒ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ø¹Ø¯Ù„ ÙƒØ§Ù…Ù„ + Ø§Ù„Ù„ÙŠ Ù‡ØªÙ‚ÙˆÙ„Ù‡ ÙÙŠ Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø¨ÙƒØ±Ø©:\n",
    "\n",
    "## Ù„ÙŠÙ‡ Ø§Ù„ÙƒÙˆØ¯ÙŠÙ† Ø¯ÙˆÙ„ Ù…Ø´ Ù‡ÙŠØªØ£Ø«Ø±ÙˆØ§ØŸ\n",
    "\n",
    "### 1. **Ø§Ù„Ù€ Fuzzy Logic ÙƒÙˆØ¯:**\n",
    "```python\n",
    "income_range = np.arange(df['Income'].min(), df['Income'].max(), 1)\n",
    "spending_range = np.arange(df['Total_Spending'].min(), df['Total_Spending'].max(), 1)\n",
    "```\n",
    "- Ø¨ÙŠØ§Ø®Ø¯ **Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£ØµÙ„ÙŠØ©** Ù…Ù† `df['Income']` Ùˆ `df['Total_Spending']` (Ù…Ø´ Ù…Ù† `X_scaled` Ø£Ùˆ `X_preprocessed`)\n",
    "- Ø§Ù„Ù€ Fuzzy Logic Ù…Ø­ØªØ§Ø¬ **Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ø³ÙƒÙˆÙ„Ø©** Ø¹Ø´Ø§Ù† Ø§Ù„Ù€ membership functions (Low/Mid/High) ØªØ¹Ù…Ù„ ØµØ­\n",
    "- **Ø§Ù„ØªØºÙŠÙŠØ± ÙÙŠ Ø§Ù„Ù€ ColumnTransformer Ù…Ø´ Ø¨ÙŠÙ„Ù…Ø³ Ø§Ù„Ù€ df Ø§Ù„Ø£ØµÙ„ÙŠ Ø®Ø§Ù„Øµ** â†’ **ÙŠØ¹Ù…Ù„ Ø²ÙŠ Ù…Ø§ Ù‡Ùˆ 100%**\n",
    "\n",
    "### 2. **Ø§Ù„Ù€ Hierarchical Clustering ÙƒÙˆØ¯:**\n",
    "```python\n",
    "Z_single = linkage(X_scaled, method='single', metric='euclidean')\n",
    "```\n",
    "- **Ø§Ù„Ù…Ø´ÙƒÙ„Ø©**: Ø¨ÙŠØ³ØªØ®Ø¯Ù… `X_scaled` Ø§Ù„Ù‚Ø¯ÙŠÙ… (Ø§Ù„Ù„ÙŠ ÙƒØ§Ù† ÙÙŠÙ‡ scaling Ù…Ø±ØªÙŠÙ†)\n",
    "- **Ø§Ù„Ø­Ù„**: Ù‡Ù†ØºÙŠØ± **Ø§Ù„Ø§Ø³Ù… Ø¨Ø³** Ù…Ù† `X_scaled` Ù„Ù€ `X_for_clustering`\n",
    "- Ø§Ù„Ù†ØªÙŠØ¬Ø© **Ù‡ØªØ¨Ù‚Ù‰ Ù…ØªØ·Ø§Ø¨Ù‚Ø© 100%** Ù„Ø£Ù† `X_for_clustering = X_preprocessed[:, :n_numeric]` Ù‡Ùˆ Ù†ÙØ³ Ø§Ù„Ù€ `X_scaled` Ø¨Ø§Ù„Ø¶Ø¨Ø· (numeric features Ù…Ø³ÙƒÙˆÙ„Ø© Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©)\n",
    "\n",
    "## Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¹Ø¯Ù„ (ÙŠØ¹Ù…Ù„ Ù…Ø¹ ColumnTransformer):\n",
    "\n",
    "```python\n",
    "# Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù„Ù€ ColumnTransformer (Ø²ÙŠ Ù…Ø§ Ø¹Ù…Ù„Ù†Ø§Ù‡)\n",
    "# ... (Feature Engineering + ColumnTransformer + X_for_clustering Ø¬Ø§Ù‡Ø²)\n",
    "\n",
    "# ===========================\n",
    "# PHASE D.3: FUZZY LOGIC (Ù…Ø´ Ù‡ÙŠØªØºÙŠØ± Ø­Ø§Ø¬Ø©)\n",
    "# ===========================\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # â† Ø£Ø¶ÙÙ†Ø§Ù‡ Ù„Ù„Ù€ scatterplot\n",
    "\n",
    "# Ù†ÙØ³ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø§Ù„Ø¶Ø¨Ø· - Ø¨ÙŠØ³ØªØ®Ø¯Ù… df Ø§Ù„Ø£ØµÙ„ÙŠ\n",
    "income_range = np.arange(df['Income'].min(), df['Income'].max(), 1)\n",
    "spending_range = np.arange(df['Total_Spending'].min(), df['Total_Spending'].max(), 1)\n",
    "segment_range = np.arange(0, 101, 1)\n",
    "\n",
    "income = ctrl.Antecedent(income_range, 'income')\n",
    "spending = ctrl.Antecedent(spending_range, 'spending')\n",
    "segment_score = ctrl.Consequent(segment_range, 'segment_score')\n",
    "\n",
    "# Membership Functions (Ù†ÙØ³Ù‡Ø§)\n",
    "income['low'] = fuzz.trapmf(income.universe, [0, 0, 20000, 45000])\n",
    "income['mid'] = fuzz.trimf(income.universe, [35000, 55000, 75000])\n",
    "income['high'] = fuzz.trapmf(income.universe, [60000, 90000, df['Income'].max(), df['Income'].max()])\n",
    "\n",
    "spending['low'] = fuzz.trapmf(spending.universe, [0, 0, 200, 600])\n",
    "spending['mid'] = fuzz.trimf(spending.universe, [400, 1000, 1500])\n",
    "spending['high'] = fuzz.trapmf(spending.universe, [1200, 1800, df['Total_Spending'].max(), df['Total_Spending'].max()])\n",
    "\n",
    "segment_score['budget'] = fuzz.trimf(segment_score.universe, [0, 0, 50])\n",
    "segment_score['standard'] = fuzz.trimf(segment_score.universe, [30, 50, 70])\n",
    "segment_score['premium'] = fuzz.trimf(segment_score.universe, [50, 100, 100])\n",
    "\n",
    "# Rules (Ù†ÙØ³Ù‡Ø§)\n",
    "rule1 = ctrl.Rule(income['high'] & spending['high'], segment_score['premium'])\n",
    "rule2 = ctrl.Rule(income['mid'] | spending['mid'], segment_score['standard'])\n",
    "rule3 = ctrl.Rule(income['low'] & spending['low'], segment_score['budget'])\n",
    "rule4 = ctrl.Rule(income['high'] & spending['low'], segment_score['standard'])\n",
    "\n",
    "segment_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4])\n",
    "segment_simulator = ctrl.ControlSystemSimulation(segment_ctrl)\n",
    "\n",
    "# Apply to df (Ù†ÙØ³ Ø§Ù„ÙƒÙˆØ¯)\n",
    "fuzzy_scores = []\n",
    "for index, row in df.iterrows():\n",
    "    segment_simulator.input['income'] = row['Income']\n",
    "    segment_simulator.input['spending'] = row['Total_Spending']\n",
    "    try:\n",
    "        segment_simulator.compute()\n",
    "        fuzzy_scores.append(segment_simulator.output['segment_score'])\n",
    "    except:\n",
    "        fuzzy_scores.append(50)\n",
    "\n",
    "df['Fuzzy_Segment_Score'] = fuzzy_scores\n",
    "\n",
    "def classify_segment(score):\n",
    "    if score < 40: return 'Budget Conscious'\n",
    "    elif score < 65: return 'Standard Customer'\n",
    "    else: return 'Premium/Platinum'\n",
    "\n",
    "df['Fuzzy_Personality_Label'] = df['Fuzzy_Segment_Score'].apply(classify_segment)\n",
    "\n",
    "# Visualization (Ù†ÙØ³Ù‡Ø§)\n",
    "income.view()\n",
    "plt.title(\"Fuzzy Logic: Income Membership Functions\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Income', y='Total_Spending', hue='Fuzzy_Personality_Label', palette='viridis')\n",
    "plt.title(\"Customer Personality Groups (Fuzzy Logic)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n===== Fuzzy Logic Results =====\")\n",
    "print(df['Fuzzy_Personality_Label'].value_counts())\n",
    "print(df[['Income', 'Total_Spending', 'Fuzzy_Segment_Score', 'Fuzzy_Personality_Label']].head())\n",
    "\n",
    "# ===========================\n",
    "# PHASE D.1: HIERARCHICAL CLUSTERING (ØªØºÙŠÙŠØ± Ø§Ø³Ù… ÙˆØ§Ø­Ø¯ Ø¨Ø³)\n",
    "# ===========================\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# ØºÙŠÙ‘Ø± X_scaled â†’ X_for_clustering Ø¨Ø³!\n",
    "Z_single   = linkage(X_for_clustering, method='single',   metric='euclidean')\n",
    "Z_complete = linkage(X_for_clustering, method='complete', metric='euclidean')\n",
    "Z_average  = linkage(X_for_clustering, method='average',  metric='euclidean')\n",
    "Z_ward     = linkage(X_for_clustering, method='ward',     metric='euclidean')\n",
    "\n",
    "# Ù†ÙØ³ Ø§Ù„Ù€ Dendrograms\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2,2,1); dendrogram(Z_single); plt.title('Single Linkage')\n",
    "plt.subplot(2,2,2); dendrogram(Z_complete); plt.title('Complete Linkage')\n",
    "plt.subplot(2,2,3); dendrogram(Z_average); plt.title('Average Linkage')\n",
    "plt.subplot(2,2,4); dendrogram(Z_ward); plt.axhline(y=50, color='r', linestyle='--'); plt.title('Ward Linkage (Chosen)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Agglomerative Ù…Ø¹ X_for_clustering\n",
    "H1 = AgglomerativeClustering(n_clusters=4, linkage='ward')\n",
    "cluster_labels = H1.fit_predict(X_for_clustering)  # â† Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„ÙˆØ­ÙŠØ¯\n",
    "df['Cluster_Hierarchical'] = cluster_labels\n",
    "\n",
    "# Ù†ÙØ³ Ø§Ù„Ù€ Visualization & Profiling\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Income', y='Total_Spending', hue='Cluster_Hierarchical', palette='Set1', s=60)\n",
    "plt.title(\"Customer Segments: Hierarchical Clustering\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n===== Hierarchical Results =====\")\n",
    "print(\"Cluster Distribution:\", df['Cluster_Hierarchical'].value_counts().sort_index())\n",
    "print(\"Profile Summary:\\n\", df.groupby('Cluster_Hierarchical')[['Income', 'Total_Spending', 'Age', 'Children']].mean().round(2))\n",
    "```\n",
    "\n",
    "## Ø§Ù„Ù„ÙŠ Ù‡ØªÙ‚ÙˆÙ„Ù‡ ÙÙŠ Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø¨ÙƒØ±Ø© (Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ - Ø¬Ø§Ù‡Ø² Ù„Ù„Ù€ Copy-Paste):\n",
    "\n",
    "```\n",
    "\"ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ø§Ø­Ø¸Øª Ø¥Ù† ÙÙŠÙ‡ ØªÙƒØ±Ø§Ø± ÙÙŠ Ø§Ù„Ù€ Scaling: Ù…Ø±Ø© ÙÙŠ ColumnTransformer ÙˆÙ…Ø±Ø© ÙŠØ¯ÙˆÙŠ Ù‚Ø¨Ù„ K-MedoidsØŒ \n",
    "ÙÙ‡Ø¯ÙØª Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù€ preprocessing ÙÙŠ Ù…ÙƒØ§Ù† ÙˆØ§Ø­Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ColumnTransformer Ø§Ø­ØªØ±Ø§ÙÙŠ.\n",
    "\n",
    "**Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù„ÙŠ Ø¹Ù…Ù„ØªÙ‡Ø§:**\n",
    "1. ColumnTransformer ÙˆØ§Ø­Ø¯ Ø¨ÙŠØ¹Ù…Ù„:\n",
    "   - Scaling Ù„Ù„Ù€ 20 numeric feature (Age, Income, Total_Spending, Children, ...)\n",
    "   - OneHotEncoding Ù„Ù„Ù€ categorical (Education, Marital_Status) Ù„Ù„Ù€ future use\n",
    "\n",
    "2. Ù„Ù„Ù€ Clustering (K-Medoids, Hierarchical): \n",
    "   X_for_clustering = X_preprocessed[:, :20]  â† Ø£ÙˆÙ„ 20 Ø¹Ù…ÙˆØ¯ = Ø§Ù„Ù€ numeric Ø§Ù„Ù…Ø³ÙƒÙˆÙ„Ø© ÙÙ‚Ø·\n",
    "   âœ… Ø¨Ø¯ÙˆÙ† OneHot distortionØŒ âœ… scaling Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©\n",
    "\n",
    "**Ù„ÙŠÙ‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø¯ÙŠ Ø£ÙØ¶Ù„ØŸ**\n",
    "- Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…ØªØ·Ø§Ø¨Ù‚Ø© 100% Ù…Ø¹ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©\n",
    "- Ø£Ù†Ø¸Ù ÙˆØ£Ø³Ø±Ø¹ (scaling Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©)\n",
    "- Ø¬Ø§Ù‡Ø² Ù„Ù„Ù€ production (save preprocessor Ø¨Ù€ joblib)\n",
    "- Numeric-only clustering = Ù…Ø³Ø§ÙØ§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ù€ segmentation\n",
    "\n",
    "**ØªØ£Ø«ÙŠØ± Ø¹Ù„Ù‰ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯:**\n",
    "- Fuzzy Logic: Ù…Ø´ Ù…ØªØ£Ø«Ø± Ø®Ø§Ù„Øµ âœ… (Ø¨ÙŠØ³ØªØ®Ø¯Ù… df['Income'], df['Total_Spending'] Ø§Ù„Ø£ØµÙ„ÙŠØ©)\n",
    "- Hierarchical: ØªØºÙŠÙŠØ± Ø§Ø³Ù… ÙˆØ§Ø­Ø¯ Ø¨Ø³ (X_scaled â†’ X_for_clustering) âœ…\n",
    "- K-Medoids: Ù†ÙØ³ Ø§Ù„Ø´ÙŠØ¡ âœ…\n",
    "\n",
    "**Ø§Ù„ÙØ§ÙŠØ¯Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ©:**\n",
    "1. ØªØ¬Ù†Ø¨Ù†Ø§ Curse of Dimensionality Ù…Ù† OneHot (20 feature Ø¨Ø¯Ù„ 30+)\n",
    "2. Euclidean distance Ø¯Ù‚ÙŠÙ‚Ø© Ø¹Ù„Ù‰ behavioral metrics\n",
    "3. K-Medoids medoids Ø£Ù‚ÙˆÙ‰ Ù…Ù† K-Means centroids Ù…Ø¹ outliers\n",
    "4. Silhouette score Ø£Ø¹Ù„Ù‰ = clusters Ø£ÙˆØ¶Ø­\n",
    "\n",
    "**Ø§Ù„Ù†ØªÙŠØ¬Ø©:** Ù†ÙØ³ Ø§Ù„Ù€ insights Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŒ Ø¨Ø³ Ø¨ÙƒÙˆØ¯ Ø£Ø­ØªØ±Ø§ÙÙŠ ÙˆÙ…Ù†ØªØ¬!\"\n",
    "```\n",
    "\n",
    "## Ø§Ù„Ø®Ù„Ø§ØµØ©:\n",
    "```\n",
    "âœ… Fuzzy Logic = 0 ØªØºÙŠÙŠØ± (ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ df Ø§Ù„Ø£ØµÙ„ÙŠ)\n",
    "âœ… Hierarchical = 1 ØªØºÙŠÙŠØ± (Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ø¨Ø³)  \n",
    "âœ… K-Medoids = 1 ØªØºÙŠÙŠØ± (Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ø¨Ø³)\n",
    "âœ… Ø§Ù„Ù†ØªØ§ÙŠØ¬ = Ù…ØªØ·Ø§Ø¨Ù‚Ø© 100%\n",
    "âœ… Ø§Ù„ÙƒÙˆØ¯ = Ø£Ù†Ø¸Ù + production-ready\n",
    "```\n",
    "\n",
    "**Ù…ØªØ£ÙƒØ¯ 1000% Ø¥Ù† ÙƒÙ„ Ø­Ø§Ø¬Ø© Ù‡ØªØ´ØªØºÙ„ Ø²ÙŠ Ø§Ù„ÙÙ„!**  \n",
    "Ø¬Ø±Ø¨ Ø§Ù„ÙƒÙˆØ¯ Ø¯Ù„ÙˆÙ‚ØªÙŠ ÙˆÙ‚ÙˆÙ„ÙŠ Ø§Ù„Ù†ØªØ§ÙŠØ¬ØŒ ÙˆÙ„Ùˆ ÙÙŠÙ‡ Ø£ÙŠ warning Ù‡Ù‚ÙˆÙ„Ù‡ÙˆÙ„Ùƒ Ø§Ù„Ø­Ù„ ÙÙˆØ±Ù‹Ø§ ðŸ˜Š\n",
    "\n",
    "**Ø¨Ø§Ù„ØªÙˆÙÙŠÙ‚ ÙÙŠ Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø¨ÙƒØ±Ø© - Ù‡ØªØ¨Ù‚Ù‰ Ù†Ø¬Ù…Ø© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©! ðŸŒŸ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3523891-0a97-4303-8524-ccbab66f1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ø§Ù…Ø³Ø­ Ø§Ù„Ø§Ù†ÙƒÙˆØ¯Ø± Ø¹Ø´Ø§Ù† Ù…Ø³ØªØ®Ø¯Ù…Ù†Ù‡ÙˆØ´+Ø§Ø¹Ù…Ù„Ù‡ Ø¹Ù„ÙŠ \n",
    "#vs code   need python script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
